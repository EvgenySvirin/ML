{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GeqjUsgn4HY"
      },
      "source": [
        "# Линейная регрессия\n",
        "__Суммарное количество баллов: 10__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmYMrZJGn4Hg"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs, make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l86n1A9Bn4Hj"
      },
      "outputs": [],
      "source": [
        "def read_data(path=\"boston.csv\"):\n",
        "    dataframe = np.genfromtxt(path, delimiter=\",\", skip_header=15)\n",
        "    np.random.seed(42)\n",
        "    np.random.shuffle(dataframe)\n",
        "    X = dataframe[:, :-1]\n",
        "    y = dataframe[:, -1]\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIDuGR68n4Hj"
      },
      "outputs": [],
      "source": [
        "def generate_synthetic(size:int, dim=6, noise=0.1):\n",
        "    X = np.random.randn(size, dim)\n",
        "    w = np.random.randn(dim + 1)\n",
        "    noise = noise * np.random.randn(size)\n",
        "    y = X.dot(w[1:]) + w[0] + noise\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3vIJt-X4dob"
      },
      "outputs": [],
      "source": [
        "X, y = read_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc7Wg91GVCGj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmYH8eEUI2zD"
      },
      "outputs": [],
      "source": [
        "# Task 1\n",
        "def mse(y_true:np.ndarray, y_predicted:np.ndarray):\n",
        "    return np.sum((y_true - y_predicted) ** 2) / y_true.shape[0]\n",
        "\n",
        "def r2(y_true:np.ndarray, y_predicted:np.ndarray):\n",
        "    diff2 = (y_true - y_predicted) ** 2\n",
        "    m = np.mean(y_true)\n",
        "    tot = np.sum((y_true - m) ** 2)\n",
        "    resid = np.sum(diff2)\n",
        "    return (tot - resid) / tot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4551JlSk4q2b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Task 1\n",
        "\n",
        "def mse(y_true:np.ndarray, y_predicted:np.ndarray):\n",
        "    return 0.0\n",
        "\n",
        "def r2(y_true:np.ndarray, y_predicted:np.ndarray):\n",
        "    return 0.0\n",
        "\n",
        "# Task 2\n",
        "\n",
        "class NormalLR:\n",
        "    def __init__(self):\n",
        "        self.weights = None # Save weights here\n",
        "    \n",
        "    def fit(self, X:np.ndarray, y:np.ndarray):\n",
        "        pass\n",
        "    \n",
        "    def predict(self, X:np.ndarray) -> np.ndarray:\n",
        "        pass\n",
        "    \n",
        "# Task 3\n",
        "\n",
        "class GradientLR:\n",
        "    def __init__(self, alpha:float, iterations=10000, l=0.):\n",
        "        self.weights = None # Save weights here\n",
        "    \n",
        "    def fit(self, X:np.ndarray, y:np.ndarray):\n",
        "        pass\n",
        "\n",
        "    def predict(self, X:np.ndarray):\n",
        "        pass\n",
        "\n",
        "# Task 4\n",
        "\n",
        "def get_feature_importance(linear_regression):\n",
        "    return []\n",
        "\n",
        "def get_most_important_features(linear_regression):\n",
        "    return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTQrXJM3n4Hk"
      },
      "source": [
        "### Задание 1 (1 балл)\n",
        "Для начала нужно понять, какую метрику для ошибки будем использовать. В нашем случае нам подойдет стандартная метрика MSE. Также чтобы оценить качество модели нам понадобится метрика $R^2$. Реализуйте обе эти метрики."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhFj_POqn4Hl"
      },
      "outputs": [],
      "source": [
        "from task import mse, r2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl6-3k-wn4Hm"
      },
      "source": [
        "### Задание 2 (3 балла)\n",
        "Теперь реализуем линейную регрессию при помощи явного решения задачи минимизации. \n",
        "\n",
        "#### Методы\n",
        "`fit(X, y)` - решает задачу минимизации $\\arg\\min_{w, b}\\sum ((w\\cdot x + b) - y)^2$. \n",
        "\n",
        "`predict(X)` - строит предсказание `y` для объектов из `X`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGk6nYF-lDKM"
      },
      "outputs": [],
      "source": [
        "def add_one_left(X):\n",
        "    return np.concatenate(([1], X))\n",
        "\n",
        "class NormalLR:\n",
        "    def __init__(self):\n",
        "        self.weights = None # Save weights here\n",
        "    \n",
        "    def fit(self, X:np.ndarray, y:np.ndarray):\n",
        "        x_ext = np.apply_along_axis(add_one_left, 1, X)\n",
        "        x_ext_tr = x_ext.transpose()\n",
        "                \n",
        "        self.x_sword =  np.dot(np.linalg.inv(np.matmul(x_ext_tr, x_ext)), x_ext_tr)\n",
        "        self.weights = np.dot(self.x_sword, y)\n",
        "    \n",
        "    def predict(self, X:np.ndarray) -> np.ndarray:\n",
        "        x_ext = np.apply_along_axis(add_one_left, 1, X)\n",
        "        return np.dot(x_ext, self.weights) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ5qQ1p3n4Hn"
      },
      "outputs": [],
      "source": [
        "from task import NormalLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg5BqJPAn4Hn"
      },
      "outputs": [],
      "source": [
        "X, y = generate_synthetic(1024)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyB5sun8n4Ho",
        "outputId": "1b7d728b-6632-4527-ad87-9bf142770f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.009749306748453547, R2: 0.9964719373674387\n"
          ]
        }
      ],
      "source": [
        "regr = NormalLR()\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "print(f\"MSE: {mse(y_test, y_pred)}, R2: {r2(y_test, y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ9rFp-gn4Hp"
      },
      "source": [
        "### Задание 3 (4 балла)\n",
        "Теперь реализуем линейную регрессию с использованием градиентного спуска с larning rate `alpha` в течении `iterations` итераций. В задании необходимо использовать регуляризацию Лассо с коэффициентом `l`.\n",
        "\n",
        "#### Методы\n",
        "`fit(X, y)` - приближает решение задачи минимизации $\\arg\\min_{w, b}\\sum ((w\\cdot x + b) - y)^2$ при помощи градиентного спуска. \n",
        "\n",
        "\n",
        "`predict(X)` - строит предсказание `y` для объектов из `X`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYzw2-dcn4Hq"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "aUKqK3JOtrQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "x = [[1, 2, 3], [1, 1, 1], [2, 2, 2]]\n",
        "y = [1, 2, 2]\n",
        "x_transformed = scaler.fit_transform(x)\n",
        "\n",
        "print(x, x_transformed)\n",
        "\n",
        "x2 = scaler.inverse_transform(x_transformed, copy=True)\n",
        "\n",
        "print(x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCXwIbP2q7WA",
        "outputId": "6d3e9667-85d2-4c84-9333-1eba0695d48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3], [1, 1, 1], [2, 2, 2]] [[-0.70710678  0.70710678  1.22474487]\n",
            " [-0.70710678 -1.41421356 -1.22474487]\n",
            " [ 1.41421356  0.70710678  0.        ]]\n",
            "[[1. 2. 3.]\n",
            " [1. 1. 1.]\n",
            " [2. 2. 2.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "x3 = myScaler(x)\n",
        "print(x3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVDg2IaO0Roc",
        "outputId": "1d59ad2e-8f11-45ad-a4fa-42fc23b30698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 2, 2], [1, 1, 1], [2, 2, 2]]\n",
            "[2 2 2]\n",
            "[1 1 1]\n",
            "[[1. 1. 1.]\n",
            " [0. 0. 0.]\n",
            " [1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyScaler:\n",
        "  def fit(self, x):\n",
        "    maxes = np.copy(x[0])\n",
        "    mines = np.copy(x[0])\n",
        "    for line in x:\n",
        "      for i in range(len(line)):\n",
        "        maxes[i] = max(maxes[i], line[i])\n",
        "        mines[i] = min(mines[i], line[i])\n",
        "    self.maxes = maxes\n",
        "    self.mines = mines\n",
        "  \n",
        "  def transform(self, x):\n",
        "    mines = self.mines\n",
        "    maxes = self.maxes\n",
        "    x_res = np.copy(np.vstack([self.mines, self.maxes])) #just for next vstack usages to work\n",
        "    for line in x:\n",
        "      row = np.array([(line[i] - mines[i]) / (maxes[i] - mines[i]) if maxes[i] != mines[i] else 0 for i in range(len(line))])\n",
        "      x_res = np.vstack([x_res, row])\n",
        "    return x_res[2:]\n",
        "\n",
        "  def fit_y(self, y):\n",
        "    self.maxY = max(y)\n",
        "    self.minY = min(y)\n",
        " \n",
        "  def transform_y(self, y):\n",
        "    return np.array([(label - self.minY) / (self.maxY - self.minY) for label in y])\n",
        "  \n",
        "  def inverse_transform_y(self, y):\n",
        "    return np.array([(label * (self.maxY - self.minY) + self.minY) for label in y])\n"
      ],
      "metadata": {
        "id": "myEdl7xzzAnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "M9BS6wjYI04q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx9YC2YH6KGJ"
      },
      "outputs": [],
      "source": [
        "class GradientLR:\n",
        "    def __init__(self, alpha:float, iterations=10000, l=0.):\n",
        "        self.alpha = alpha\n",
        "        self.iterations = iterations\n",
        "        self.l = l\n",
        "\n",
        "    def fit(self, X:np.ndarray, y:np.ndarray):\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.scaler.fit(X)\n",
        "        X = self.scaler.transform(X)\n",
        "        x_ext = np.apply_along_axis(add_one_left, 1, X)\n",
        "        self.weights = np.zeros(x_ext.shape[1])\n",
        "\n",
        "        #self.scaler.fit_y(y)\n",
        "        #y = self.scaler.transform_y(y)\n",
        "        for i in range(self.iterations):\n",
        "            y_predicted = np.dot(x_ext, self.weights)\n",
        "            gradient = np.dot(y_predicted - y, x_ext) / x_ext.shape[0]\n",
        "            gradient += np.dot(self.l, np.sign(self.weights))\n",
        "            #gradient += np.dot(self.l, np.array(self.weights))\n",
        "            self.weights -= np.dot(self.alpha, gradient)\n",
        "\n",
        "    def predict(self, X:np.ndarray):\n",
        "        X = self.scaler.transform(X)\n",
        "        if (X.shape[1] < self.weights.shape[0]):\n",
        "            X = np.apply_along_axis(add_one_left, 1, X)\n",
        "        return np.dot(X, self.weights) \n",
        "        #return self.scaler.inverse_transform_y(np.dot(X, self.weights)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcfjGBREn4Hq"
      },
      "outputs": [],
      "source": [
        "def build_plot(X_train, y_train, X_test, y_test):\n",
        "    xs = np.arange(0.0, 0.02, 0.0002)\n",
        "    errors = []\n",
        "    for x in xs:\n",
        "        regr = GradientLR(0.1, iterations=10000, l=x)\n",
        "        regr.fit(X_train, y_train)\n",
        "        errors.append(mse(y_test, regr.predict(X_test)))\n",
        "    plt.figure(figsize=(9, 4))\n",
        "    plt.xlim(xs[0], xs[-1])\n",
        "    plt.grid()\n",
        "    plt.plot(xs, errors)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ8txzZdn4Hr"
      },
      "outputs": [],
      "source": [
        "X, y = generate_synthetic(1024)\n",
        "X, X_val, y, y_val = train_test_split(X, y, train_size=0.9, shuffle=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "z7QFa1czn4Hs",
        "outputId": "8df45375-379a-43cd-9fb8-70b2812d8cef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "build_plot(X_train, y_train, X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siP8OKLRn4Ht",
        "outputId": "90f409c3-267c-4de1-d243-7107922a7385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.011010613539734083, R2: 0.9981701599975706\n"
          ]
        }
      ],
      "source": [
        "regr = GradientLR(0.1, iterations=10000)\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "print(f\"MSE: {mse(y_test, y_pred)}, R2: {r2(y_test, y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghCaw906z-ks"
      },
      "source": [
        "### Задание 4 (2 балла)\n",
        "Линейная регрессия является методом, который можно интерпретировать основываясь на значениях весов модели. Реализуйте метод, который будет упорядочивать признаки по их важности от наибольшей важности к наименьшей.\n",
        "\n",
        "Обратите внимание, что такая интерпретация имеет смысл только если данные предварительно нормализованы, а также в признаках нет мультиколлинеарности (если используете обычную линейную регрессию).\n",
        "\n",
        "#### Методы\n",
        "`get_feature_importance` - метод, который вычисляет важность для каждого признака. Принимает на вход обученную линейную регрессию, возвращает список значений метрики важности признаков.\n",
        "\n",
        "`get_most_important_features`- метод, который упорядочевает признаки по их важности в порядке убывания. Принимает на вход обученную линейную регрессию, возвращает упорядоченный список, состоящий из индексов признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HDGLiadz-kt"
      },
      "outputs": [],
      "source": [
        "def get_feature_importance(linear_regression):\n",
        "    return np.abs(linear_regression.weights[1:])\n",
        "\n",
        "def get_most_important_features(linear_regression):\n",
        "    return list(zip(*sorted(enumerate(get_feature_importance(linear_regression)), key=lambda x :x[1], reverse=True)))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bV9CRekz-kt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcefa752-120a-49a3-d852-76c640cead7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.4515153  0.77371078 0.05516782 1.4815458  1.64594382 0.11396867]\n",
            "(4, 3, 1, 0, 5, 2)\n"
          ]
        }
      ],
      "source": [
        "regr = NormalLR()\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "\n",
        "print(get_feature_importance(regr))\n",
        "print(get_most_important_features(regr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCJVVTvYz-kt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68709557-575b-4453-f054-73431b4c1ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.56456896  4.85596185  0.38279804  9.1519915  10.36314278  0.65613005]\n",
            "(4, 3, 1, 0, 5, 2)\n"
          ]
        }
      ],
      "source": [
        "regr = GradientLR(0.1, iterations=10000)\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "\n",
        "print(get_feature_importance(regr))\n",
        "print(get_most_important_features(regr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmjSHt9rn4Ht"
      },
      "source": [
        "### Дополнительно\n",
        "Протесируйте оба метода на данных `boston.csv`, для градиентного спуска постройте график зависимости ошибки от коэффициента регуляризации. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk2TeC7Hn4Hu"
      },
      "outputs": [],
      "source": [
        "X, y = read_data()\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZCb_5KVn4Hu"
      },
      "outputs": [],
      "source": [
        "regr = NormalLR()\n",
        "regr.fit(X_train, y_train)\n",
        "print(f\"MSE: {mse(y_val, y_pred)}, R2: {r2(y_test, y_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMkUfayxn4Hv"
      },
      "outputs": [],
      "source": [
        "build_plot(X_train, y_train, X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtPBlBPkn4Hw"
      },
      "outputs": [],
      "source": [
        "regr = GradientLR(0.1, iterations=10000)\n",
        "regr.fit(X_train, y_train)\n",
        "print(f\"MSE: {mse(y_val, y_pred)}, R2: {r2(y_test, y_val)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d63Ei1yEn4Hw"
      },
      "source": [
        "Проинтерпритируйте полученные результаты. Опишите влияние каждого признака на результат предсказания."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19Ci6i5Wn4Hw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}